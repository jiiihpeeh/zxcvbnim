import tables
import options
import os
import math
import strutils
import sequtils
import sugar
from jsony import toJson, fromJson
import json
import algorithm
import supersnappy
#[ usage:

generates frequency based json (zxcvbn"s ranked dictionary file) from word frequency data.
data dir should contain frequency counts, as generated by the scripts.

DICTIONARIES controls which frequency data will be included and at maximum how many tokens
per dictionary.

If a token appears in multiple frequency lists, it will only appear once in emitted .coffee file,
in the dictionary where it has lowest rank.

Short tokens, if rare, are also filtered out. If a token has higher rank than 10**(token.length),
it will be excluded because a bruteforce match would have given it a lower guess score.

A warning will be printed if DICTIONARIES contains a dictionary name that doesn"t appear in
passed data dir, or vice-versa. ]#

# maps dict name to num words. None value means "include all words"const DICTIONARIES : Table[Option]
var DICTIONARIES : OrderedTable[string, Option[int]]

proc getDics():auto=
    let settingBase = "DictionarySettings.json"
    var dics : OrderedTable[string, Option[int]]
    if not (fileExists(joinPath(getCurrentDir(), settingBase))):
        let numericseq : seq[Option[int]] = @[some(30000), some(30000), some(30000),
                                                some(10000), none(int), none(int)]
        let keyseq : seq[string] = @["us_tv_and_film", "english_wikipedia",
                    "passwords", "surnames", "male_names", "female_names"]
        
        for kv in zip(keyseq, numericseq):
            let (k ,v) = kv
            dics[k] = v
        writeFile(settingBase, dics.toJson())
    else:
        var  dictf : string
        if fileExists(settingBase):
            dictf = settingBase
        else:
            dictf = joinPath(getCurrentDir(), settingBase)
        dics = readFile(dictf).fromJson(OrderedTable[string, Option[int]])

    DICTIONARIES = dics


type 
    DirSeq = seq[tuple[kind: PathComponent, path: string]]
    FreqListTable = OrderedTable[string,OrderedTable[string,int]]
    FrequencyTable = OrderedTable[string, seq[string]]
    RankedTable = OrderedTable[string, OrderedTable[string,int]]

proc listFiles(path : string): DirSeq=
    return toSeq(walkDir(path, relative=true)) 



# returns {list_name: {token: rank}}, as tokens and ranks occur in each file.
proc parseFrequencyLists(dataDir: string):FreqListTable{.inline.}=
    var freqLists = initOrderedTable[string,OrderedTable[string,int]]()
    for fileInfo in listFiles(dataDir):
        let
            (_, freqListName, _) = splitFile(fileInfo.path)
        if  not DICTIONARIES.contains(freqListName):
            echo "Warning $1 appears in $2 but not in DICTIONARY settings. Excluding." % [freqListName, dataDir]
            continue

        var 
            tokenToRank = initOrderedTable[string, int]()
            lineCount = 0
        let filePath = joinPath(dataDir, fileInfo.path)
        #defer: fileContent.close()

        var token : string
        for line in lines(filePath):
            #let splitted = filter(line.split(" ", 1), proc(x: string): bool = x.runeLen > 0)
            let splitted = line.split(" ", 1)
            if splitted.len > 0:
                lineCount += 1
                token = splitted[0]
                tokenToRank[token] = lineCount
        freqLists[freqListName] = tokenToRank
    for freqListName in DICTIONARIES.keys():
        if not freqLists.contains(freqListName):
            let msg = "Warning $1 appears in DICTIONARY settings but not in $2 directory. Excluding."  % [freqListName, dataDir]
            echo msg
    return freqLists

func isRareAndShort(token: string, rank:int):bool=
    let test = float(rank) >= pow(10.0, float(token.len)) 
    return test

func hasCommaOrDoubleQuote(token: string): bool =
    # hax, switch to csv or similar if this excludes too much.
    # simple comma joining has the advantage of being easy to process
    # client-side w/o needing a lib, and so far this only excludes a few
    # very high-rank tokens eg "ps8,000" at rank 74868 from wikipedia list.
    if token.contains(",") or token.contains("""""""):
        return true
    return false

proc filterFrequencyLists[T](freqLists : T):FrequencyTable{.inline.}=
#[     filters frequency data according to:
        - filter out short tokens if they are too rare.
        - filter out tokens if they already appear in another dict
          at lower rank.
        - cut off final freq_list at limits set in DICTIONARIES, if any. ]#

    var
        filteredTokenAndRank = initOrderedTable[string, seq[tuple[token:string, rank:int]]]()  # maps {name: [(token, rank), ...]}
        tokenCount = initOrderedTable[string,int]()  # maps freq list name: current token count.
        resultDict = initOrderedTable[string, seq[string]]()
        minimumRank = initTable[string,int]()  # maps token -> lowest token rank across all freq lists
        minimumName = initTable[string,string]()  # maps token -> freq list name with lowest token rank

    for name in freqLists.keys():
        filteredTokenAndRank[name] = @[]
        tokenCount[name] = 0

    for name in freqLists.keys():
        let subFreqLists = freqLists[name]
        for token in subFreqLists.keys():
            let rank = subFreqLists[token]
            if not minimumRank.hasKey(token):
                assert not minimumName.hasKey(token)
                minimumRank[token] = rank
                minimumName[token] = name
            else:
                assert minimumName.hasKey(token)
                assert minimumName[token] != name #, "same token occurs multiple times in %s" % name
                let minRank = minimumRank[token]
                if rank < minRank:
                    minimumRank[token] = rank
                    minimumName[token] = name
    
    for name in freqLists.keys():
        let tokenToRank = freqLists[name]
        for token in tokenToRank.keys():
            let rank =  tokenToRank[token]
            if minimumName[token] != name:
                continue
            if isRareAndShort(token, rank) or hasCommaOrDoubleQuote(token):
                continue
            filteredTokenAndRank[name].add((token, rank))
            tokenCount[name] += 1

    for name in filteredTokenAndRank.keys():
        let tokenRankPairs = filteredTokenAndRank[name]
        var 
            sortTokenRankPairs = tokenRankPairs.sortedByIt(it[1])
        let
            cutoffLimit = DICTIONARIES[name]
        if cutoffLimit.isSome() and sortTokenRankPairs.len > cutoffLimit.get():
            sortTokenRankPairs = sortTokenRankPairs[0..cutoffLimit.get() - 1]
        resultDict[name] = collect(newSeq):
            for pair in sortTokenRankPairs: pair[0]  # discard rank post-sort
    return resultDict


proc buildRankedTable(orderedList: seq[string]): OrderedTable[string,int] =
    var 
        index = 1
        indextable  = initOrderedTable[string, int]()
    for i in orderedList:
        indextable[i] = index
        index.inc
    return indexTable

proc addFrequencyLists(frequencyLists : FrequencyTable):  RankedTable  =
    var ranked  = initOrderedTable[string, OrderedTable[string, int]]()
    for name in keys(frequencyLists):
        ranked[name] = buildRankedTable(frequencyLists[name])
    return ranked

proc frequencyWrite*(dirData: string, outDir: string)=
    getDics()
    let
        unfilteredFreqLists = parseFrequencyLists(dirData)
        freqLists = filterFrequencyLists(unfilteredFreqLists)
        rankedLists = addFrequencyLists(freqLists)
    let serialized = rankedLists.toJson()
    #writeFile(joinPath(outDir,"DictFreq.json"), serialized)
    writeFile(joinPath(outDir,"DictFreq.json.snappy"), compress(serialized))

